{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c914d536-3d59-4da1-bdd2-7add3707a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddpm_full_finetune_toy.py\n",
    "import math, os, random, numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976d6100-c816-4b08-ab74-b89602d9fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 0) Utilities\n",
    "# ----------------------------\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.makedirs(\"samples\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52aaf97f-2b3c-4908-ac36-d2bf4d8efaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1) Toy datasets (no downloads)\n",
    "# ----------------------------\n",
    "def make_blob(h, w, radius, cx, cy):\n",
    "    \"\"\"Return a binary circle mask.\"\"\"\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    return ((x - cx)**2 + (y - cy)**2) <= radius**2\n",
    "\n",
    "def make_square(h, w, side, cx, cy):\n",
    "    \"\"\"Return a binary square mask centered at (cx,cy).\"\"\"\n",
    "    x0, y0 = int(cx - side//2), int(cy - side//2)\n",
    "    mask = np.zeros((h, w), dtype=bool)\n",
    "    mask[max(y0,0):min(y0+side,h), max(x0,0):min(x0+side,w)] = True\n",
    "    return mask\n",
    "\n",
    "def render_toy(h=32, w=32, kind=\"blobs\"):\n",
    "    img = np.zeros((h, w), dtype=np.float32)\n",
    "    if kind == \"blobs\":\n",
    "        # 1â€“3 circles with random radii/centers\n",
    "        for _ in range(np.random.randint(1, 4)):\n",
    "            r = np.random.randint(3, 8)\n",
    "            cx, cy = np.random.randint(r, w-r), np.random.randint(r, h-r)\n",
    "            img[make_blob(h, w, r, cx, cy)] = 1.0\n",
    "    elif kind == \"squares\":\n",
    "        for _ in range(np.random.randint(1, 3)):\n",
    "            s = np.random.randint(4, 10)\n",
    "            cx, cy = np.random.randint(s//2, w-s//2), np.random.randint(s//2, h-s//2)\n",
    "            img[make_square(h, w, s, cx, cy)] = 1.0\n",
    "    elif kind == \"mixed\":\n",
    "        if np.random.rand() < 0.5:\n",
    "            return render_toy(h, w, \"blobs\")\n",
    "        else:\n",
    "            return render_toy(h, w, \"squares\")\n",
    "    # slight blur-ish antialias: distance transform lite\n",
    "    img = img + 0.1 * np.random.randn(h, w).astype(np.float32)\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return img\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, n=2000, kind=\"blobs\"):\n",
    "        self.n = n; self.kind = kind\n",
    "    def __len__(self): return self.n\n",
    "    def __getitem__(self, idx):\n",
    "        img = render_toy(kind=self.kind)  # [H,W] in [0,1]\n",
    "        img = 2.0 * img - 1.0             # to [-1,1]\n",
    "        img = torch.from_numpy(img)[None, ...]  # [1,H,W]\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06b92cb4-69ed-48e9-ad15-b59c7d8867d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2) Tiny UNet (2D, single-channel)\n",
    "# ----------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch), nn.SiLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch), nn.SiLU(),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.pool = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        return self.conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_period=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.lin1 = nn.Linear(dim, dim*4)\n",
    "        self.lin2 = nn.Linear(dim*4, dim)\n",
    "    def forward(self, t):\n",
    "        # sinusoidal embedding\n",
    "        half = self.dim // 2\n",
    "        freqs = torch.exp(-math.log(10000) * torch.arange(0, half, device=t.device).float() / half)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        emb = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        emb = self.lin2(F.silu(self.lin1(emb)))\n",
    "        return emb\n",
    "\n",
    "class UNetSmall(nn.Module):\n",
    "    def __init__(self, in_ch=1, base=32, time_dim=64):\n",
    "        super().__init__()\n",
    "        self.time_mlp = TimeEmbedding(time_dim)\n",
    "        self.inc = DoubleConv(in_ch, base)\n",
    "        self.down1 = Down(base, base*2)\n",
    "        self.down2 = Down(base*2, base*4)\n",
    "        self.bot  = DoubleConv(base*4, base*4)\n",
    "        self.up2  = Up(base*4 + base*2, base*2)\n",
    "        self.up1  = Up(base*2 + base, base)\n",
    "        self.outc = nn.Conv2d(base, in_ch, 1)\n",
    "        # FiLM-like time conditioning\n",
    "        # self.t_to_scale = nn.Linear(time_dim, base*3)\n",
    "        # self.t_to_shift = nn.Linear(time_dim, base*3)\n",
    "        # FiLM per stage (channels match each feature map)\n",
    "        self.s1, self.b1 = nn.Linear(time_dim, base),    nn.Linear(time_dim, base)\n",
    "        self.s2, self.b2 = nn.Linear(time_dim, base*2),  nn.Linear(time_dim, base*2)\n",
    "        self.s3, self.b3 = nn.Linear(time_dim, base*4),  nn.Linear(time_dim, base*4)\n",
    "\n",
    "    def film(self, x, s, b):\n",
    "        return x * (1 + s[..., None, None]) + b[..., None, None]\n",
    "\n",
    "    def apply_time(self, xs, t_emb):\n",
    "        scales = self.t_to_scale(t_emb).chunk(3, dim=-1)\n",
    "        shifts = self.t_to_shift(t_emb).chunk(3, dim=-1)\n",
    "        outs = []\n",
    "        for x, s, b in zip(xs, scales, shifts):\n",
    "            outs.append(x * (1 + s[..., None, None]) + b[..., None, None])\n",
    "        return outs\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_mlp(t)\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        xb = self.bot(x3)\n",
    "        # time condition on three stages (simple demo)\n",
    "        #x1, x2, xb = self.apply_time([x1, x2, xb], t_emb)\n",
    "        # new: per-stage FiLM with matching channels\n",
    "        x1 = self.film(x1, self.s1(t_emb), self.b1(t_emb))\n",
    "        x2 = self.film(x2, self.s2(t_emb), self.b2(t_emb))\n",
    "        xb = self.film(xb, self.s3(t_emb), self.b3(t_emb))\n",
    "        u2 = self.up2(xb, x2)\n",
    "        u1 = self.up1(u2, x1)\n",
    "        return self.outc(u1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea45658-952a-4ac5-8e75-88208abc7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3) DDPM schedule & helpers\n",
    "# ----------------------------\n",
    "class DDPM:\n",
    "    def __init__(self, timesteps=200, beta_start=1e-4, beta_end=0.02, device=DEVICE):\n",
    "        self.T = timesteps\n",
    "        beta = torch.linspace(beta_start, beta_end, self.T, device=device)\n",
    "        alpha = 1.0 - beta\n",
    "        self.register(alpha, beta)\n",
    "\n",
    "    def register(self, alpha, beta):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.alphabar = torch.cumprod(alpha, dim=0)\n",
    "        self.sqrt_ab = torch.sqrt(self.alphabar)                           # [T]\n",
    "        self.sqrt_1mab = torch.sqrt(torch.clamp(1.0 - self.alphabar, 1e-20))  # [T]\n",
    "        self.one_over_sqrt_a = torch.sqrt(1.0 / self.alpha)\n",
    "        # length T-1, valid for t >= 1\n",
    "        self.posterior_var = (\n",
    "                 self.beta[1:] * (1.0 - self.alphabar[:-1])\n",
    "                  / torch.clamp(1.0 - self.alphabar[1:], 1e-20)\n",
    "             )\n",
    "    def q_sample(self, x0, t, noise=None):\n",
    "        if noise is None: noise = torch.randn_like(x0)\n",
    "        sqrt_ab = self.sqrt_ab[t].view(-1,1,1,1)\n",
    "        sqrt_1mab = self.sqrt_1mab[t].view(-1,1,1,1)\n",
    "        return sqrt_ab * x0 + sqrt_1mab * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, model, x_t, t):\n",
    "        # predict noise\n",
    "        eps = model(x_t, t)\n",
    "        a_t = self.alpha[t].view(-1,1,1,1)\n",
    "        ab_t = self.alphabar[t].view(-1,1,1,1)\n",
    "        one_over_sqrt_a = self.one_over_sqrt_a[t].view(-1,1,1,1)\n",
    "        # predicted x0\n",
    "        x0_hat = (x_t - torch.sqrt(torch.clamp(1 - ab_t, 1e-20)) * eps) / torch.sqrt(torch.clamp(ab_t, 1e-20))\n",
    "        mean   = one_over_sqrt_a * (x_t - (1 - a_t) / torch.sqrt(torch.clamp(1 - ab_t, 1e-20)) * eps)\n",
    "        # final step: return clean prediction\n",
    "        if (t == 0).all():\n",
    "          return x0_hat\n",
    "        var = self.posterior_var[(t-1).clamp(min=0)].view(-1,1,1,1)\n",
    "        \n",
    "        noise = torch.randn_like(x_t)\n",
    "        return mean + torch.sqrt(torch.clamp(var, 1e-20)) * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, n=16, shape=(1,32,32)):\n",
    "        model.eval()\n",
    "        x = torch.randn(n, *shape, device=DEVICE)\n",
    "        for ti in reversed(range(self.T)):\n",
    "            t = torch.full((n,), ti, device=DEVICE, dtype=torch.long)\n",
    "            x = self.p_sample(model, x, t)\n",
    "        return x.clamp(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b411736-3585-4050-a0e3-417fd5a47b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4) Training / Fine-tuning loops\n",
    "# ----------------------------\n",
    "def train_epoch(model, ddpm, loader, opt):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for x0 in loader:\n",
    "        x0 = x0.to(DEVICE)\n",
    "        b = x0.size(0)\n",
    "        t = torch.randint(0, ddpm.T, (b,), device=DEVICE, dtype=torch.long)\n",
    "        noise = torch.randn_like(x0)\n",
    "        x_t = ddpm.q_sample(x0, t, noise)\n",
    "        pred = model(x_t, t)\n",
    "        loss = F.mse_loss(pred, noise)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        total += loss.item() * b\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "def save_grid(tensor, path, nrow=4):\n",
    "    # tensor: [N,1,H,W] in [-1,1]\n",
    "    x = (tensor.add(1).mul(0.5)).cpu().numpy()\n",
    "    N,C,H,W = x.shape\n",
    "    rows = (N + nrow - 1) // nrow\n",
    "    canvas = np.ones((rows*H, nrow*W), dtype=np.float32)\n",
    "    idx = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(nrow):\n",
    "            if idx < N:\n",
    "                canvas[r*H:(r+1)*H, c*W:(c+1)*W] = x[idx,0]\n",
    "                idx += 1\n",
    "    plt.figure(figsize=(nrow, rows))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(canvas, vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0c4853d-47be-4506-abf2-9b221b29378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pretrain] epoch 01 loss=0.4832\n",
      "[pretrain] epoch 02 loss=0.2481\n",
      "[pretrain] epoch 03 loss=0.2010\n",
      "[pretrain] epoch 04 loss=0.1857\n",
      "[pretrain] epoch 05 loss=0.1676\n",
      "saved: samples/pretrained_on_blobs.png\n",
      "[finetune] epoch 01 loss=0.1564\n",
      "[finetune] epoch 02 loss=0.1373\n",
      "[finetune] epoch 03 loss=0.1381\n",
      "[finetune] epoch 04 loss=0.1311\n",
      "[finetune] epoch 05 loss=0.1285\n",
      "saved: samples/finetuned_on_squares.png\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    set_seed(3)\n",
    "    # Pretrain on domain A (blobs)\n",
    "    trainA = ToyDataset(n=2000, kind=\"blobs\")\n",
    "    trainB = ToyDataset(n=2000, kind=\"squares\")  # OOD target for fine-tune\n",
    "    loaderA = DataLoader(trainA, batch_size=64, shuffle=True, num_workers=0)\n",
    "    loaderB = DataLoader(trainB, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "    model = UNetSmall(in_ch=1, base=32, time_dim=64).to(DEVICE)\n",
    "    ddpm  = DDPM(timesteps=200, beta_start=1e-4, beta_end=2e-2, device=DEVICE)\n",
    "\n",
    "    # ---------- Stage 1: pretrain (a few epochs just to see learning) ----------\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "    for epoch in range(5):\n",
    "        loss = train_epoch(model, ddpm, loaderA, opt)\n",
    "        print(f\"[pretrain] epoch {epoch+1:02d} loss={loss:.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        samples = ddpm.sample(model, n=16, shape=(1,32,32))\n",
    "    save_grid(samples, \"samples/pretrained_on_blobs.png\")\n",
    "    print(\"saved:\", \"samples/pretrained_on_blobs.png\")\n",
    "\n",
    "    # ---------- Stage 2: FULL fine-tune on domain B (ALL params trainable) ----------\n",
    "    # (This is \"full FT\": we do NOT freeze any layers.)\n",
    "    opt_ft = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    for epoch in range(5):\n",
    "        loss = train_epoch(model, ddpm, loaderB, opt_ft)\n",
    "        print(f\"[finetune] epoch {epoch+1:02d} loss={loss:.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        samples_ft = ddpm.sample(model, n=16, shape=(1,32,32))\n",
    "    save_grid(samples_ft, \"samples/finetuned_on_squares.png\")\n",
    "    print(\"saved:\", \"samples/finetuned_on_squares.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd28c3-b466-4fca-8f35-267c1b02a0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_renew",
   "language": "python",
   "name": "torch_gpu_renew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
